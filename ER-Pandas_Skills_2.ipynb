{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam Review: Pandas Skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and create helper function. Code for displaying dataframes from Python Data Science Handbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class display(object):\n",
    "    \"\"\"Display HTML representation of multiple objects\"\"\"\n",
    "    template = \"\"\"<div style=\"float: left; padding: 10px;\">\n",
    "    <p style='font-family:\"Courier New\", Courier, monospace'>{0}</p>{1}\n",
    "    </div>\"\"\"\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        return '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n",
    "                         for a in self.args)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '\\n\\n'.join(a + '\\n' + repr(eval(a))\n",
    "                           for a in self.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic operations\n",
    "\n",
    "Questions 1 - 8 are based on the DataFrame `data` as created below.  Assume that each successive questions input is being executed in a notebook and that each questionâ€™s `In[]` expressions are evaluated in the order shown.  Therefore any changes to DataFrames by prior questions must be considered for the current question.  \n",
    "\n",
    "For each question, evaluate the code provided and write the question number and its expected output in the output cell provided. If an expression is illegal and will result in an error write ERROR as the expected output.\n",
    "\n",
    "While you could simply run these expressions, we encourage you to at least attempt to answers these questions directly since this will assist you in your exam preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "area_dict = {'California': 423967, 'Texas': 695662, 'New York': 141297,\n",
    "             'Florida': 170312, 'Illinois': 149995}\n",
    "population_dict = {'California': 38332521,\n",
    "                   'Texas': 26448193,\n",
    "                   'New York': 19651127,\n",
    "                   'Florida': 19552860,\n",
    "                   'Illinois': 12882135}\n",
    "population = pd.Series(population_dict)\n",
    "area = pd.Series(area_dict)\n",
    "data = pd.DataFrame({'population': population,\n",
    "              'area': area})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1:2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.index)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['foo'] = pd.Series({'California': 'Blue',\n",
    "                         'Texas': 'Red',\n",
    "                         'Illinois': 'Blue'})\n",
    "data.iloc[2:4,2:3]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT = data.T\n",
    "dataT.iloc[2,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.area < 150000, ['area', 'foo']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_pop = data.population > 25000000\n",
    "large_pop"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT.loc['population':'foo', :'Florida']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**---------------------------------------------------------------**\n",
    "**Questions 9 - 13** are based on the DataFrames `df1` and `df2` as created below.  For each question, evaluate the code provided and write the question number and its expected output in the output cell provided. If an expression is illegal and will result in an error write ERROR as the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa'],\n",
    "                    'group': ['ART', 'HR', 'EE']})\n",
    "df2 = pd.DataFrame({'employee': ['Lisa', 'Sue'],\n",
    "                    'dept': ['Lecturer', 'Admin']})\n",
    "display('df1', 'df2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = pd.merge(df1, df2)\n",
    "m1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "9:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = pd.merge(df1, df2, how='inner')\n",
    "m2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 11**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = pd.merge(df1, df2, how='outer')\n",
    "m3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "11:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 12**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4 = pd.merge(df1, df2, how='left')\n",
    "m4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "12:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 13**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m5 = pd.merge(df1, df2, how='right')\n",
    "m5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "13:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**---------------------------------------------------------------**\n",
    "For each question, evaluate the code provided and write the question number and its expected output in the output cell provided. If an expression is illegal and will result in an error write ERROR as the expected output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 14**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data': range(6)}, columns=['key', 'data'])\n",
    "df.groupby('key').sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "14:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 15**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').aggregate(['min', np.median, max])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "15:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'A': 'vowel', 'B': 'consonant', 'C': 'consonant'}\n",
    "df2 = df.set_index('key')\n",
    "df2.groupby(mapping).sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "16:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 17**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby(str.lower).max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "17:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 18**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['peter', None, 'MARY', 'gUIDO']\n",
    "names =  pd.Series(data)\n",
    "names.str.capitalize()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "18:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 19**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monte = pd.Series(['Graham Chapman', 'John Cleese', 'Michael Palin'])\n",
    "monte.str.split()[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "19:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
